{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a42135",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### $Load$ $Libraries$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af023786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from datasets) (0.33.4)\n",
      "Requirement already satisfied: packaging in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/lathanasopoulou/capstone/.conda_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.7.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling fsspec-2025.7.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.7.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [datasets]/17\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 attrs-25.3.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 multidict-6.6.3 multiprocess-0.70.16 pandas-2.3.1 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c1dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f444702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67c203b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?',\n",
       " 'answer': 'Maila read 12 x 2 = <<12*2=24>>24 pages today.\\nSo she was able to read a total of 12 + 24 = <<12+24=36>>36 pages since yesterday.\\nThere are 120 - 36 = <<120-36=84>>84 pages left to be read.\\nSince she wants to read half of the remaining pages tomorrow, then she should read 84/2 = <<84/2=42>>42 pages.\\n#### 42'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53bd0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adb2b991b974beebf9c141cc3e0aca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "socratic/train-00000-of-00001.parquet:   0%|          | 0.00/2.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f19e321fc8c41d7a6f1c0ee32597205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "socratic/test-00000-of-00001.parquet:   0%|          | 0.00/487k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f968301cd53e41e2a3db493131148e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4809c17153144731ac260951a6dd4018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"openai/gsm8k\", \"socratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fdaf722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 7473\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee395f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': 'How many clips did Natalia sell in May? ** Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nHow many clips did Natalia sell altogether in April and May? ** Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfaf06a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b173204e8a1a4248bb72dab2ee91cd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b30f42c70b49899ff0d50970a70ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/131k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6e3c557f4f4efb835354fb6dc62200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/34.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d863e2a949f484c9f9595e1fdc48651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adef97f0524047faa8d56a66feb32c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"yimingzhang/asdiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af867a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'target', 'label'],\n",
       "        num_rows: 301\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44ac58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Question: Rachel bought 8 music albums online. If each album had 2 songs, how many songs did she buy total?\\nAnswer:',\n",
       " 'target': '<<8*2>>16',\n",
       " 'label': '16'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "171e3287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3366c93abc445ab9c01bc0f84b1e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c05891c4834049a208543aec500a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3b5c197575422e88f68d392e738679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/34.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42dbe6ec9be4622b6e7792e58383772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9c3116e35e4d4bb06c22920de40ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"garrethlee/MAWPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51d4c890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1417\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 355\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b0b3d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '2 birds were sitting on the fence . 4 more birds came to join them . How many birds are sitting on the fence ?',\n",
       " 'answer': '2 + 4 = 6 #### 6'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de26aaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6773b4382748b29a6022e0f796a2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3b0534cd2f4abc9bd53a5d0b88afb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3673600b1954491a5786c91ee2ba992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f8ea5cf73e4c64ac177b70a1570b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/151k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2ab897d51c4b29a23a552eb9fef850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d38c337a4b4a5fb9099b5f08923a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f154e4c634a942ed8c175f4189d5743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"tau/commonsense_qa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4ce8f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### $Load$ $BREAKQ$ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e2e77",
   "metadata": {},
   "source": [
    "The distractor version contains a `train` set and a `validation` set. \n",
    "* **Train Set:** Provides the question, the answer, and the two gold standard context paragraphs required to answer it. Here there are no distractors.\n",
    "* **Validation Set:** Contains a question and ~10 paragraphs. The 2 are the gold paragraphs, and 8 are carefully chosen distractors. The model's task is to read these 10 and answer.\n",
    "\n",
    "This version does not contain a `test set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3ee018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will  download the dataset\n",
    "dataset_distractor = load_dataset(\"hotpot_qa\", \"distractor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c78d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_distractor.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd8921",
   "metadata": {},
   "source": [
    "Each example contains:  \n",
    "\n",
    "1. **`id`**: A unique identifier for the question.  \n",
    "2. **`question`**: The question that needs to be answered.  \n",
    "3. **`answer`**: The correct answer to the question.  \n",
    "4. **`type`**: The type of question—either:  \n",
    "   - **`comparison`** (compares two things)  \n",
    "   - **`bridge`** (connects facts to find the answer).  \n",
    "5. **`level`**: How hard the question is (`easy`, `medium`, or `hard`).  \n",
    "6. **`supporting_facts`**: The key facts that prove the answer is correct. Each fact is given as:  \n",
    "   - **`title`**: The title of the paragraph where the fact is found.  \n",
    "   - **`sent_id`**: The sentence number (starting from 0) inside that paragraph.  \n",
    "7. **`context`**: All the paragraphs the model must read to find the answer. Each paragraph has:  \n",
    "   - **`title`**: The paragraph’s title.  \n",
    "   - **`sentences`**: A list of sentences in that paragraph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac0d4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'answer', 'type', 'level', 'supporting_facts', 'context'],\n",
       "    num_rows: 90447\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_distractor[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26fa8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5a7a06935542990198eaf050\n",
      "Level: medium\t | Type: comparison\n",
      "==================================================\n",
      "\n",
      "Question: Which magazine was started first Arthur's Magazine or First for Women?\n",
      "\n",
      "Answer: Arthur's Magazine\n",
      "\n",
      "\n",
      "Supporting Facts\n",
      "--------------------\n",
      "To answer the question, the model needs to find the following information:\n",
      "\n",
      "  - From Article 'Arthur's Magazine':\n",
      "    \"Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.\"\n",
      "\n",
      "  - From Article 'First for Women':\n",
      "    \"First for Women is a woman's magazine published by Bauer Media Group in the USA.\"\n"
     ]
    }
   ],
   "source": [
    "example_distractor = dataset_distractor[\"train\"][0]\n",
    "\n",
    "print(f\"ID: {example_distractor['id']}\")\n",
    "print(f\"Level: {example_distractor['level']}\\t | Type: {example_distractor['type']}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nQuestion: {example_distractor['question']}\")\n",
    "print(f\"\\nAnswer: {example_distractor['answer']}\")\n",
    "\n",
    "print(\"\\n\\nSupporting Facts\")\n",
    "print(\"-\"*20)\n",
    "print(\"To answer the question, the model needs to find the following information:\")\n",
    "\n",
    "# Extract the titles and sentence IDs for the supporting facts\n",
    "supporting_titles = example_distractor['supporting_facts']['title']\n",
    "supporting_sent_ids = example_distractor['supporting_facts']['sent_id']\n",
    "\n",
    "# Get the full context list\n",
    "context_titles = example_distractor['context']['title']\n",
    "context_sentences = example_distractor['context']['sentences']\n",
    "\n",
    "# Loop through the supporting facts and find the full sentences\n",
    "for i in range(len(supporting_titles)):\n",
    "\tfact_title = supporting_titles[i]\n",
    "\tfact_sent_id = supporting_sent_ids[i]\n",
    "\t\n",
    "\t# Find the index of the article in the main context\n",
    "\ttry:\n",
    "\t\tcontext_index = context_titles.index(fact_title)\n",
    "\t\t# Get the actual sentence\n",
    "\t\tsentence = context_sentences[context_index][fact_sent_id]\n",
    "\t\tprint(f\"\\n  - From Article '{fact_title}':\")\n",
    "\t\tprint(f\"    \\\"{sentence}\\\"\")\n",
    "\texcept ValueError:\n",
    "\t\tprint(f\"Error: Could not find the context for title '{fact_title}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c086c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### $Load$ $HotpotQA$ - $Fullwiki$ $version$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a104a64",
   "metadata": {},
   "source": [
    "The fullwiki version contains a `train` set, a `validation` set and a `test` set. \n",
    "* **Train Set:** The train set is the same as in the distractor version. Provides the question, the answer, and the two gold standard context paragraphs required to answer it. Here there are no distractors.\n",
    "* **Validation Set:** The 10 paragraphs in the validation set are not the ground truth context. They are the output of a standard, baseline Information Retrieval (IR) system. The dataset creators ran their own simple search engine over all of Wikipedia to find the 10 most likely paragraphs for each question. \n",
    "* **Test Set:** We are given only the questions. There is no context provided. The system must implement its own retrieval module to search all the articles of the Wikipedia corpus, find the relevant information, and then answer the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918ea2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fullwiki = load_dataset(\"hotpot_qa\", \"fullwiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e509a56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fullwiki.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d603132",
   "metadata": {},
   "source": [
    "Each example contains the same features as in the distractor version: \n",
    "\n",
    "1. **`id`**: A unique identifier for the question.  \n",
    "2. **`question`**: The question that needs to be answered.  \n",
    "3. **`answer`**: The correct answer to the question.  \n",
    "4. **`type`**: The type of question—either:  \n",
    "   - **`comparison`** (compares two things)  \n",
    "   - **`bridge`** (connects facts to find the answer).  \n",
    "5. **`level`**: How hard the question is (`easy`, `medium`, or `hard`).  \n",
    "6. **`supporting_facts`**: The key facts that prove the answer is correct. Each fact is given as:  \n",
    "   - **`title`**: The title of the paragraph where the fact is found.  \n",
    "   - **`sent_id`**: The sentence number (starting from 0) inside that paragraph.  \n",
    "7. **`context`**: All the paragraphs the model must read to find the answer. Each paragraph has:  \n",
    "   - **`title`**: The paragraph’s title.  \n",
    "   - **`sentences`**: A list of sentences in that paragraph.  \n",
    "\n",
    "$Attention$ : $The$ **$supporting$ _ $facts$** $and$ **$answers$** $are$ $not$ $present$ $in$ $the$ $test$ $set.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dbda7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'answer', 'type', 'level', 'supporting_facts', 'context'],\n",
       "    num_rows: 90447\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fullwiki[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e353af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5a7a06935542990198eaf050\n",
      "Level: medium\t | Type: comparison\n",
      "==================================================\n",
      "\n",
      "Question: Which magazine was started first Arthur's Magazine or First for Women?\n",
      "\n",
      "Answer: Arthur's Magazine\n",
      "\n",
      "\n",
      "Supporting Facts\n",
      "--------------------\n",
      "To answer the question, the model needs to find the following information:\n",
      "\n",
      "  - From Article 'Arthur's Magazine':\n",
      "    \"Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.\"\n",
      "\n",
      "  - From Article 'First for Women':\n",
      "    \"First for Women is a woman's magazine published by Bauer Media Group in the USA.\"\n"
     ]
    }
   ],
   "source": [
    "example_fullwiki = dataset_fullwiki[\"train\"][0]\n",
    "\n",
    "print(f\"ID: {example_fullwiki['id']}\")\n",
    "print(f\"Level: {example_fullwiki['level']}\\t | Type: {example_fullwiki['type']}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nQuestion: {example_fullwiki['question']}\")\n",
    "print(f\"\\nAnswer: {example_fullwiki['answer']}\")\n",
    "\n",
    "print(\"\\n\\nSupporting Facts\")\n",
    "print(\"-\"*20)\n",
    "print(\"To answer the question, the model needs to find the following information:\")\n",
    "\n",
    "# Extract the titles and sentence IDs for the supporting facts\n",
    "supporting_titles = example_fullwiki['supporting_facts']['title']\n",
    "supporting_sent_ids = example_fullwiki['supporting_facts']['sent_id']\n",
    "\n",
    "# Get the full context list\n",
    "context_titles = example_fullwiki['context']['title']\n",
    "context_sentences = example_fullwiki['context']['sentences']\n",
    "\n",
    "# Loop through the supporting facts and find the full sentences\n",
    "for i in range(len(supporting_titles)):\n",
    "\tfact_title = supporting_titles[i]\n",
    "\tfact_sent_id = supporting_sent_ids[i]\n",
    "\t\n",
    "\t# Find the index of the article in the main context\n",
    "\ttry:\n",
    "\t\tcontext_index = context_titles.index(fact_title)\n",
    "\t\t# Get the actual sentence\n",
    "\t\tsentence = context_sentences[context_index][fact_sent_id]\n",
    "\t\tprint(f\"\\n  - From Article '{fact_title}':\")\n",
    "\t\tprint(f\"    \\\"{sentence}\\\"\")\n",
    "\texcept ValueError:\n",
    "\t\tprint(f\"Error: Could not find the context for title '{fact_title}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2551076",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### $Distractor$ $vs.$ $Fullwiki$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2df9b9",
   "metadata": {},
   "source": [
    "* In the **distractor** setting, the 10 paragraphs are a \"hand-picked\" reasoning challenge where the 2 gold paragraphs are guaranteed to be present.\n",
    "\n",
    "* In the **fullwiki** validation setting, the 10 paragraphs are the pre-computed results of a simple search engine. They are provided for convenience during development and to create a fair test of reading comprehension on a *retrieved* set of documents, where the necessary information is not guaranteed to be present.\n",
    "\n",
    "\n",
    "\n",
    "For our project, which focuses on decomposition (a reasoning task), sticking with the **distractor** data seems to be a valid approach, since we are primarily testing the model's ability to reason over a given context, not its ability to retrieve documents from all of Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47285582",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### $Dataset$ $Creation$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246334d1",
   "metadata": {},
   "source": [
    "*First, we will create a few_shot_examples.json file by manually decomposing questions from the training set, using their supporting sentences as a guide. Next, we will build a separate evaluation dataset from the validation set, following the same manual decomposition process.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes a single example from the HotpotQA 'distractor' set.\n",
    "# It extracts the ID, question, answer, and reconstructs the list of \n",
    "# supporting sentences needed to arrive at the correct answer.\n",
    "# It returns these elements in a structured dictionary.\n",
    "\n",
    "def decomposition_prompt(example_distractor):\n",
    "\tid = example_distractor['id']\n",
    "\tquestion = example_distractor['question']\n",
    "\tanswer = example_distractor['answer']\n",
    "\tsupporting_sentences = []\n",
    "\tfor title, sent_id in zip(example_distractor[\"supporting_facts\"][\"title\"], example_distractor[\"supporting_facts\"][\"sent_id\"]):\n",
    "\t\tfor context_title, sentences in zip(example_distractor[\"context\"][\"title\"], example_distractor[\"context\"][\"sentences\"]):\n",
    "\t\t\tif title == context_title: \n",
    "\t\t\t\tsupporting_sentences.append(sentences[sent_id].strip())\n",
    "\n",
    "\tsupporting_sentences.append(f\"Aggregating the above we conclude that the answer is: {answer}\")\n",
    "\n",
    "\tdict_prompt = {\"id\":id, \"question\":question, \"supporting_sentences\":supporting_sentences, \"answer\":answer}\n",
    "\t\n",
    "\treturn dict_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78698d",
   "metadata": {},
   "source": [
    "##### $Few$ $Shot$ $Examples$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e818dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0719569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in dataset_distractor[\"train\"]:\n",
    "    if len(few_shot_examples) < 5:\n",
    "        few_shot_examples.append(decomposition_prompt(example))\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82ae6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples[0][\"decomposition\"] = [\n",
    "    \t\t\t\"When was Arthur's Magazine started?\",\n",
    "                \"When was First for Women magazine started?\",\n",
    "                \"Which of the two starting dates is earlier?\"]\n",
    "\n",
    "few_shot_examples[1][\"decomposition\"] = [\n",
    "                \"Which hotel company is the Oberoi family associated with?\",\n",
    "                \"Where is the head office of The Oberoi Group located?\"]\n",
    "\n",
    "few_shot_examples[2][\"decomposition\"] = [\n",
    "    \t\t\t\"Who created the character Milhouse in 'The Simpsons'?\",\n",
    "                \"After whom did Matt Groening name the character Milhouse?\"]\n",
    "\n",
    "few_shot_examples[3][\"decomposition\"] = [\n",
    "\t\t\t\t\"Who was James Henry Miller?\",\n",
    "                \"Who was James Henry Miller's wife?\",\n",
    "                \"What was James Henry Miller's wife nationality?\"]\n",
    "\n",
    "few_shot_examples[4][\"decomposition\"] = [\n",
    "                \"What chemical is Cadmium Chloride slightly soluble in?\",\n",
    "                \"What is another name for this chemical?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4785702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved!\n"
     ]
    }
   ],
   "source": [
    "filename = \"hotpot_few_shot.json\"\n",
    "folder = \"../HotpotQA_dataset/\"\n",
    "\n",
    "# Construct the full path for the file\n",
    "full_path = os.path.join(folder, filename)\n",
    "\n",
    "# Save the file\n",
    "with open(full_path, 'w', encoding='utf-8') as f:\n",
    "\tjson.dump(few_shot_examples, f, ensure_ascii=False, indent=4)\n",
    "print(\"Results have been saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8698724",
   "metadata": {},
   "source": [
    "##### $Evaluation$ $Examples$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dbf63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in dataset_distractor[\"validation\"]:\n",
    "    if len(evaluation) < 5:\n",
    "        evaluation.append(decomposition_prompt(example))\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a91fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation[0][\"decomposition\"] = [\n",
    "    \t\t\t\"What nationality Scott Derrickson had?\",\n",
    "                \"What nationality Ed Wood had?\",\n",
    "                \"Was the nationality the same?\"]\n",
    "\n",
    "evaluation[1][\"decomposition\"] = [\n",
    "                \"Who potrayed Caroliss Archer in the film Kiss and Tell?\",\n",
    "                \"What governement position was held by her?\"]\n",
    "\n",
    "evaluation[2][\"decomposition\"] = [\n",
    "    \t\t\t\"What book series has companion books, which narrate the story of an enslaved alien species?\",\n",
    "                \"Is this book series classified as science fantasy and written for young adults?\",\n",
    "                \"Is this series narrated in the first person?\"]\n",
    "\n",
    "evaluation[3][\"decomposition\"] = [\n",
    "\t\t\t\t\"What is Laleli Mosque?\",\n",
    "                \"Where is Laleli Mosque located?\"\n",
    "                \"What is Esma Sultan Mansion?\",\n",
    "                \"Where is Esma Sultan Mansion located?\"\n",
    "                \"Are they located in the same neighborhood?\"]\n",
    "\n",
    "evaluation[4][\"decomposition\"] = [\n",
    "                \"Who directed the the romantic comedy 'Big Stone Gap'?\",\n",
    "                \"In what New York city is the director located?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42ed39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved!\n"
     ]
    }
   ],
   "source": [
    "filename = \"hotpot_dataset.json\"\n",
    "folder = \"../HotpotQA_dataset/\"\n",
    "\n",
    "# Construct the full path for the file\n",
    "full_path = os.path.join(folder, filename)\n",
    "\n",
    "# Save the file\n",
    "with open(full_path, 'w', encoding='utf-8') as f:\n",
    "\tjson.dump(evaluation, f, ensure_ascii=False, indent=4)\n",
    "print(\"Results have been saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
